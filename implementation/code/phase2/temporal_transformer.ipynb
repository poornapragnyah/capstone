{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "433cf354-9a20-4230-a324-c194db161c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformer Hyperparameters - You will choose these\n",
    "# Ensure TRANSFORMER_D_MODEL matches (n_channels * GCN_out_features) from previous step\n",
    "# If your GCN out_features is 64, then 62 * 64 = 3968\n",
    "TRANSFORMER_D_MODEL = 62 * 64 \n",
    "TRANSFORMER_NHEAD = 8         # Must divide TRANSFORMER_D_MODEL evenly\n",
    "TRANSFORMER_NUM_LAYERS = 3    # Number of TransformerEncoderLayer blocks\n",
    "TRANSFORMER_DIM_FEEDFORWARD = 4 * TRANSFORMER_D_MODEL # Typically 2x or 4x d_model\n",
    "TRANSFORMER_DROPOUT = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1d0d300-0822-402b-add7-0003dfe96fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class TemporalTransformer(nn.Module):\n",
    "    def __init__(self, d_model, nhead, num_encoder_layers, dim_feedforward, dropout=0.1):\n",
    "        super(TemporalTransformer, self).__init__()\n",
    "        \n",
    "        # Define a single Transformer Encoder Layer block\n",
    "        # batch_first=False means input is (Sequence Length, Batch Size, Embedding Dimension)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model, \n",
    "            nhead=nhead,\n",
    "            dim_feedforward=dim_feedforward,\n",
    "            dropout=dropout,\n",
    "            batch_first=False # Keep this as False to match the default PyTorch Transformer API example\n",
    "                              # (Sequence Length, Batch Size, Embedding Dimension)\n",
    "        )\n",
    "        \n",
    "        # Stack multiple encoder_layer blocks to create the full Transformer Encoder\n",
    "        self.transformer_encoder = nn.TransformerEncoder(\n",
    "            encoder_layer, \n",
    "            num_layers=num_encoder_layers\n",
    "        )\n",
    "        \n",
    "    def forward(self, src):\n",
    "        # Input 'src' is EXPECTED to already be in the shape (n_time_steps, batch_size, d_model)\n",
    "        # This reshaping logic should occur in the STGTEncoder, *before* calling TemporalTransformer.\n",
    "        \n",
    "        # Pass the input directly through the Transformer Encoder\n",
    "        # The output 'output' will have the same shape as 'src'\n",
    "        output = self.transformer_encoder(src)\n",
    "        \n",
    "        # Return the sequence of processed embeddings\n",
    "        # Shape: (n_time_steps, batch_size, d_model)\n",
    "        return output \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70d265c7-6fb5-4fb3-b493-d75920ec498f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Testing TemporalTransformer ---\n",
      "TemporalTransformer instantiated with d_model=3968, nhead=8, num_layers=3\n",
      "Dummy input sequence shape: torch.Size([400, 4, 3968])\n",
      "Output sequence shape of TemporalTransformer: torch.Size([400, 4, 3968])\n",
      "TemporalTransformer test passed: Output shape matches expected shape!\n",
      "--- TemporalTransformer Test Complete ---\n"
     ]
    }
   ],
   "source": [
    "# temporal_transformer.py (continued)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"--- Testing TemporalTransformer ---\")\n",
    "\n",
    "    # Use the hyperparameters defined earlier\n",
    "    d_model = TRANSFORMER_D_MODEL\n",
    "    nhead = TRANSFORMER_NHEAD\n",
    "    num_encoder_layers = TRANSFORMER_NUM_LAYERS\n",
    "    dim_feedforward = TRANSFORMER_DIM_FEEDFORWARD\n",
    "    dropout = TRANSFORMER_DROPOUT\n",
    "\n",
    "    # Instantiate the TemporalTransformer\n",
    "    temporal_transformer = TemporalTransformer(\n",
    "        d_model=d_model,\n",
    "        nhead=nhead,\n",
    "        num_encoder_layers=num_encoder_layers,\n",
    "        dim_feedforward=dim_feedforward,\n",
    "        dropout=dropout\n",
    "    )\n",
    "    print(f\"TemporalTransformer instantiated with d_model={d_model}, nhead={nhead}, num_layers={num_encoder_layers}\")\n",
    "\n",
    "    # Create a dummy input tensor\n",
    "    # Mimics the shape (n_time_steps, batch_size, d_model)\n",
    "    dummy_n_time_steps = 400 # Your EEG time steps\n",
    "    dummy_batch_size = 4\n",
    "    dummy_d_model = d_model # This should match TRANSFORMER_D_MODEL\n",
    "\n",
    "    dummy_input_sequence = torch.randn(dummy_n_time_steps, dummy_batch_size, dummy_d_model)\n",
    "    print(f\"Dummy input sequence shape: {dummy_input_sequence.shape}\")\n",
    "\n",
    "    # Pass dummy data through the TemporalTransformer\n",
    "    output_sequence = temporal_transformer(dummy_input_sequence)\n",
    "\n",
    "    # Print the shape of the output\n",
    "    print(f\"Output sequence shape of TemporalTransformer: {output_sequence.shape}\")\n",
    "\n",
    "    # Expected output shape should be the same as input: (dummy_n_time_steps, dummy_batch_size, dummy_d_model)\n",
    "    expected_shape = (dummy_n_time_steps, dummy_batch_size, dummy_d_model)\n",
    "    if output_sequence.shape == expected_shape:\n",
    "        print(\"TemporalTransformer test passed: Output shape matches expected shape!\")\n",
    "    else:\n",
    "        print(f\"TemporalTransformer test FAILED: Expected {expected_shape}, got {output_sequence.shape}\")\n",
    "\n",
    "    print(\"--- TemporalTransformer Test Complete ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3db6271-684a-460c-9616-39b4c3ca6a76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Capstone venv",
   "language": "python",
   "name": "venv_name"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
